Summary of Linear Thompson Sampling:
Model: LOF_1
  Mean: [ 0.03515993  0.00743143  0.02739614  0.0223044   0.02291807  0.07896838
  0.02559185  0.02239873  0.03105317  0.02329091  0.00209027  0.06803599
  0.02780436  0.05520493  0.05570236  0.07262555  0.05645742  0.03273641
  0.01488909  0.02247444  0.00426993  0.01496233  0.07799964 -0.01420837
  0.04723526  0.03178506  0.0233855   0.02256792  0.02509478  0.04752067
  0.04482912  0.03049039  0.03008109  0.05733967  0.04559139  0.00620639
  0.03805255  0.04212572  0.02987144 -0.00085731  0.01518508  0.03730677
  0.0361338   0.02294723  0.03900517  0.00550342  0.04760697  0.0346915
  0.03017519  0.03198807 -0.00098335  0.02364194  0.01954456  0.02944002
  0.03374873  0.0556677   0.03161977  0.032422    0.06476669  0.02963218
  0.05099516  0.03335429  0.02287722  0.02244551  0.01573405  0.02723267
  0.0088057   0.02948532  0.04011098  0.02705639  0.0580072   0.03063971
  0.0317927   0.02440613  0.01776379  0.03065553  0.01352869]
Model: LOF_2
  Mean: [ 0.06162598  0.04398825  0.0295518   0.0483137   0.02374486  0.07350865
  0.00060788  0.06221308  0.01387623 -0.00646428  0.0441087   0.05314702
  0.04625215  0.01272031  0.03584281  0.03035711  0.07118218  0.08332321
  0.00783023  0.04732232  0.02536866  0.11750752  0.13839093 -0.00091964
  0.02367648  0.04555638  0.05457885  0.02441193 -0.02417398  0.0288423
  0.01141519  0.03454978  0.05823954  0.00833107  0.00488084  0.04358267
  0.03903321  0.01703702  0.01827499  0.06188507  0.02961996  0.0502559
  0.01665163  0.05347453  0.02719028  0.03859732  0.01571744  0.05243922
  0.01304144  0.00319029  0.00923964  0.05091769  0.0063282   0.01666174
  0.04548446  0.03081973  0.03159336  0.04640387  0.0755165  -0.00825593
  0.02994298  0.02285926  0.00382264  0.07197933  0.01795698  0.03366719
 -0.01348787  0.04838375  0.01868415  0.05406431  0.0021045   0.01358659
  0.02011009  0.04085861  0.04089012 -0.00891781  0.01819321]
Model: LOF_3
  Mean: [ 0.04316738  0.01602084  0.04761074 -0.01484905  0.00345476  0.02467907
  0.06659202  0.01514584  0.05372417  0.0636766   0.05822443  0.02214394
  0.00778302  0.02647208  0.05711968  0.00524035  0.06471767 -0.0121456
  0.01112672  0.03743317  0.02720707  0.02246678  0.07094821  0.02678808
  0.03329094  0.04423634  0.06021291  0.01977453  0.05503465  0.01659148
  0.00850979  0.00328629  0.05298942  0.02850157  0.03240486  0.05546055
  0.03443988  0.01495349  0.03949984  0.07050174 -0.03642249  0.02047099
  0.02640926  0.02238645  0.08719382  0.03489992  0.03581952  0.0553321
  0.03830971  0.04901814  0.04506744  0.11071185  0.02006633  0.02593229
 -0.03779475  0.00810314  0.07803135  0.02704354  0.01086077  0.01854211
  0.03392631 -0.00207341  0.05358232  0.03954934  0.03371711 -0.00817082
  0.03084349  0.0696482   0.03484704  0.09185783  0.03382281 -0.00905029
  0.01399789  0.03242748  0.02191129  0.08387647  0.04781506]
Model: LOF_4
  Mean: [ 0.01534825  0.06884326 -0.03299977 -0.00364348  0.07032219  0.02680955
  0.05055869  0.07022423  0.02168072  0.03875102  0.0386208   0.01537564
  0.06740548  0.1403719   0.0571398   0.09169408  0.0132074   0.06583984
  0.09031964  0.00468009  0.0329724   0.00545222  0.05327952  0.03538459
  0.03055619  0.07832769  0.06716276  0.00820471  0.0147099   0.02603332
  0.03429802  0.02255665 -0.02173756  0.08155198  0.01363481  0.03100439
  0.04120025  0.0814128   0.02430858  0.05925419 -0.00274623  0.09494742
  0.03181692  0.00234763  0.02576375  0.06868956  0.04358475  0.07214501
  0.03560342 -0.0569681   0.04876275  0.02179849  0.01298733  0.02035234
  0.02613581  0.0127893   0.00409715  0.07472312  0.0301195   0.07137794
  0.06446767  0.03700327  0.08636067 -0.00526208  0.05336423  0.05235347
  0.06310178  0.06114525  0.07858438  0.05582489  0.06386401  0.05557607
  0.0673744   0.10770534  0.00060224  0.05450314  0.0443576 ]
Model: NN_1
  Mean: [ 0.06739258  0.04409421 -0.00746471  0.01086292  0.03164528 -0.02527863
  0.02833017 -0.00381788 -0.0008803   0.00223816  0.044995    0.0342911
  0.07916836  0.06515404  0.01828183  0.04084196 -0.00269058  0.03702671
  0.02185162  0.04152238  0.05209434  0.04339078 -0.00162006  0.06034634
  0.02492761 -0.00536037  0.07323962  0.05609484  0.0156582   0.00297711
  0.00574695  0.02235271  0.06409741  0.0425041   0.06717796  0.06436659
  0.02327156  0.06134553  0.0124003   0.01243229  0.05893227  0.03996842
  0.06700869  0.05798846  0.04363074  0.04951937 -0.00296788  0.00901831
  0.00711808  0.04845155  0.08431008  0.01956783  0.05143562  0.00798527
  0.04056273  0.0952402   0.03925211  0.07439028  0.06142226  0.05421849
  0.02096525  0.03287314  0.02526685  0.06256064  0.02124051  0.03818916
  0.02030702  0.05303969  0.00672624 -0.00275778 -0.00771563  0.07643198
  0.02072142  0.05961146  0.01615926  0.04793651  0.02924805]
Model: NN_2
  Mean: [ 0.00247027  0.01251418  0.0048862   0.01859658  0.03101956  0.00791415
  0.02699531  0.01882119  0.01631526  0.02738598  0.01597062  0.03810836
  0.02170027  0.00113092  0.01589313  0.01557714  0.06777891  0.02882497
  0.01358498  0.00285365  0.02567274  0.01049073  0.02075326  0.01457984
 -0.00201974  0.0031288   0.00906894 -0.03084608  0.0025321   0.02914811
  0.00770754  0.01413109  0.01534697  0.0246739   0.01869057  0.01744666
  0.04098544  0.00542912  0.01369832  0.01427301  0.01752157  0.01589379
  0.02652325  0.01071082 -0.01135142  0.0039032   0.01322476 -0.0210025
  0.01412295 -0.00014123  0.02032599  0.01645216  0.01651682  0.00846525
  0.00176549  0.01773427  0.01307479  0.00945347  0.01104488  0.0181061
  0.03088312 -0.01038287  0.04238012  0.00799077  0.05198147  0.00873027
  0.02910809  0.01179023  0.0202964   0.02110246 -0.01436868  0.0166719
 -0.00949901 -0.00538646  0.00357157  0.01775241  0.01854124]
Model: NN_3
  Mean: [ 8.91663091e-02  6.93234493e-02  4.84034669e-03 -2.63954669e-02
  3.83457032e-02  1.59869188e-03  2.48539841e-02  6.29177354e-02
  3.42808824e-02  7.78159922e-03  1.21676101e-01  1.18481265e-01
  5.20468683e-02  8.36149336e-02  9.56811016e-02  1.67542426e-02
  3.38358514e-02  3.41440801e-02  7.93100946e-02  7.90732877e-02
 -1.44135624e-04  7.77251761e-02  6.61280574e-02  1.62677233e-01
  4.16799561e-02  1.12349513e-02  5.36695959e-02  1.00376962e-01
  9.43122809e-02 -4.04001170e-03  1.89648669e-01  7.59907295e-03
  4.43246755e-02  1.60263801e-01  7.47197868e-02  6.93273647e-02
  1.85090973e-02  6.19785858e-02  1.14543319e-01  4.90896005e-02
  4.48206808e-02 -1.66533639e-02  1.17755938e-01  1.46308320e-02
  5.16647858e-02 -4.57937104e-02  9.34438487e-02  4.95561395e-03
  1.72686481e-01  4.09662918e-02  1.28729143e-01  9.01271993e-02
  1.39131190e-02  1.08986478e-01  1.95773297e-02 -3.87534490e-02
  2.00135993e-02  3.26002097e-02  2.44476323e-03  5.82923063e-02
  1.03743926e-01  8.62113778e-02  9.91917203e-02  1.15658721e-01
  7.52598376e-02  5.98141694e-02  6.38046843e-02 -4.63310695e-02
  2.52120091e-02 -8.59706512e-03  7.64477025e-02  1.12735144e-01
  7.83974871e-02  6.61010561e-02  1.09147347e-01  1.10053164e-01
  1.01122489e-01]
Model: RNN_1
  Mean: [ 0.07329092  0.07543705  0.12633448  0.13462203  0.04827668  0.09057317
  0.02195022  0.06529943  0.09827212  0.06111792  0.09534537  0.11219644
  0.15942651  0.1586794   0.15329228  0.09487839 -0.00693293  0.00709457
  0.03414202 -0.02975991  0.04766783  0.00698082  0.06880262  0.04199841
  0.1232213   0.13026322  0.06051982  0.09884421  0.03734629  0.05096894
  0.11225602  0.03101568 -0.00986245  0.07540362  0.14247571  0.06319917
  0.01239833  0.05977968  0.14969911  0.08460013  0.02031256  0.02567987
  0.02385207 -0.03191831  0.01655547  0.02321257  0.07762357  0.12064431
  0.06407495  0.07744187  0.10767318  0.07970721  0.04513446  0.0541917
  0.05429121  0.05785301  0.06838254  0.04127056  0.04506044  0.15475597
 -0.03601221  0.09464003  0.01395682  0.04160025  0.05565932 -0.02049944
  0.00202089 -0.08125167  0.05136246 -0.0594326   0.05080201  0.0412872
  0.01411011  0.02885156  0.06612187  0.06879189  0.05176587]
Model: RNN_2
  Mean: [ 5.89404814e-02  6.35678949e-02  6.88156150e-02  7.78379262e-02
  7.68773522e-02  1.78141847e-02  1.50030078e-01  7.16704337e-02
  1.09284143e-01  6.90354443e-02  3.62883354e-02  1.88047954e-02
  5.56375389e-02  1.41321438e-02  2.77042877e-02  4.38988838e-02
  3.73119022e-02 -3.69639335e-02  2.69305674e-02  4.96793036e-02
  3.40475346e-02  2.21210357e-02  3.42407861e-02 -1.89863887e-02
  1.10425654e-01  8.00837182e-02 -1.18239702e-02  1.06582248e-01
  7.66104693e-02  8.10002382e-02  1.10720574e-01  4.61616167e-02
  9.19726844e-02 -4.69141243e-02  5.23857414e-03  1.10500652e-01
 -2.11958412e-02  7.77511870e-02  8.74319631e-02  4.21874407e-02
  3.91622965e-02  1.44966661e-02  6.51383687e-02  7.16433436e-02
  5.49410284e-02  6.79863096e-02  3.39960443e-03  8.36144524e-02
  7.02180629e-02  1.05135595e-01  8.21466790e-02  1.89881904e-02
  1.78808447e-01  3.35138589e-02  3.52590118e-02  6.18795482e-02
  3.02375941e-02  8.73266568e-03  1.90703806e-02  1.08911888e-02
  6.24488935e-02 -2.30373776e-02  6.92884027e-02  2.90832738e-02
  8.70736794e-02  6.20535754e-02  8.78959391e-03  1.07802334e-01
  8.03190676e-02  1.96782752e-02  4.35134923e-02  1.37920556e-01
  4.38966681e-02  8.54900197e-02 -6.31391567e-02  2.41348679e-02
  1.53677302e-04]
Model: RNN_3
  Mean: [ 0.09985663  0.04755018  0.07863907  0.04974438  0.04487047  0.04585914
 -0.02253753  0.05358843  0.05047505  0.04846645  0.07060218  0.04151038
  0.03859392  0.03016953 -0.01763254  0.01552976  0.00560921  0.04475321
  0.02487625  0.0903181   0.14848846  0.07828822  0.03645813  0.02351148
  0.02862878  0.00078831  0.03681717  0.04238102  0.00932608  0.00129156
  0.01354926  0.02013877  0.0419806   0.00101956  0.02395109  0.02811052
  0.04258925  0.01730795  0.00931912  0.03548255  0.0713938   0.01009375
  0.07996217  0.02753338  0.03281203  0.04662248  0.05201002  0.03120142
  0.0015203   0.02494934  0.06513299  0.0771518   0.05505794 -0.00206642
  0.08712264  0.06827696  0.01033524  0.05261572  0.00067752  0.0095799
  0.03812625  0.06290777  0.0538133   0.03387945  0.05146357  0.02009022
  0.10396296  0.01430345  0.08696776  0.06533179  0.08480879  0.04263227
  0.06851337 -0.01197564  0.0324232   0.00616357  0.0491539 ]
Model: RNN_4
  Mean: [ 0.03172415  0.01840395 -0.00185665  0.04361447  0.06490711  0.05338762
  0.03172457  0.01898233 -0.00729421  0.07600048 -0.00497392  0.02859605
  0.0595574   0.02446108  0.04348543  0.04577193  0.07522438  0.02469568
  0.00854984  0.0029351   0.00527452  0.04810735 -0.00721915  0.05185851
 -0.01378373  0.0085748   0.03736811  0.0407069   0.03366522  0.06291214
  0.07009517  0.00545742  0.02589818  0.03846082  0.02027463  0.07465177
  0.04589892  0.03011439  0.05712527  0.05258876  0.02064898  0.05424635
  0.01693501  0.10649954  0.00526759  0.05857485  0.00347392  0.03176453
  0.01238045  0.07138594  0.06427225  0.07743049  0.0422559   0.12087404
  0.05147098  0.02555267  0.00990635  0.05399092  0.03618471  0.07332755
  0.13277505  0.09046412  0.06821617  0.03286196  0.04129044  0.03650715
  0.04470956  0.07003845 -0.01439373  0.03365282  0.05002588  0.02929206
  0.05663052  0.1163865   0.04087999  0.0632342   0.03749245]
choses models for each round
['NN_1', 'NN_1', 'RNN_3', 'RNN_1', 'NN_3', 'RNN_3', 'LOF_3', 'LOF_4', 'RNN_4', 'LOF_2', 'RNN_4', 'RNN_2', 'RNN_2', 'RNN_1', 'LOF_3', 'NN_3', 'LOF_3', 'LOF_1', 'RNN_1', 'LOF_3', 'LOF_4', 'RNN_1', 'NN_1', 'NN_3', 'NN_3', 'NN_2', 'RNN_1', 'LOF_1', 'LOF_4', 'LOF_1', 'RNN_2', 'LOF_1', 'LOF_2', 'NN_1', 'LOF_1', 'LOF_4', 'RNN_2', 'RNN_4', 'RNN_1', 'LOF_2', 'NN_1', 'RNN_4', 'RNN_1', 'LOF_3', 'RNN_1', 'RNN_1', 'RNN_4', 'NN_1', 'LOF_2', 'NN_3', 'LOF_3', 'LOF_4', 'RNN_1', 'NN_3', 'LOF_4', 'LOF_4', 'LOF_2', 'NN_2', 'NN_3', 'LOF_2', 'LOF_4', 'LOF_4', 'LOF_4', 'NN_1', 'RNN_3', 'LOF_2', 'NN_3', 'RNN_4', 'LOF_2', 'RNN_2', 'LOF_4', 'RNN_3', 'RNN_1', 'NN_3', 'NN_3', 'NN_3', 'LOF_3', 'LOF_4', 'RNN_2', 'LOF_4', 'RNN_2', 'NN_3', 'RNN_3', 'NN_3', 'LOF_3', 'RNN_2', 'RNN_1', 'NN_1', 'NN_3', 'RNN_1', 'RNN_3', 'NN_3', 'LOF_4', 'LOF_2', 'RNN_4', 'LOF_1', 'LOF_3', 'RNN_2', 'LOF_2', 'LOF_4']

Models ranked by mean score:
1. NN_3 with score 0.4637850368587291
2. RNN_1 with score 0.4573785836387025
3. RNN_2 with score 0.3446917186719415
4. LOF_4 with score 0.21845245060489513
5. RNN_4 with score 0.202713578299867
6. RNN_3 with score 0.1961086631141693
7. NN_1 with score 0.14482112634629216
8. LOF_3 with score 0.14242107588800945
9. LOF_2 with score 0.14161201619821864
10. LOF_1 with score 0.10080535524263731
11. NN_2 with score 0.0323346423351918

 evaluation for models over the current test data:
[np.int64(3873), np.int64(1700), np.int64(1699), np.int64(1737), np.int64(1711), np.int64(1703), np.int64(3873), np.int64(1737), np.int64(1737), np.int64(1737), np.int64(3873)]
 f1_score list for models over the current test data:
{'NN_3': np.float64(0.7938383455989159), 'RNN_1': np.float64(0.43331692060590216), 'RNN_2': np.float64(0.4360145281599529), 'LOF_4': np.float64(0.04267920293149906), 'RNN_4': np.float64(0.427975160699019), 'RNN_3': np.float64(0.43626121332244233), 'NN_1': np.float64(0.786135987376247), 'LOF_3': np.float64(0.04267920293149906), 'LOF_2': np.float64(0.04267920293149906), 'LOF_1': np.float64(0.04267920293149906), 'NN_2': np.float64(0.7900167852956004)}
 pr_score list for models over the current test data:
{'NN_3': np.float64(0.46108073323561555), 'RNN_1': np.float64(0.8010115849471713), 'RNN_2': np.float64(0.7968316542407875), 'LOF_4': np.float64(0.7464091500158341), 'RNN_4': np.float64(0.8156304995077654), 'RNN_3': np.float64(0.8069392558219932), 'NN_1': np.float64(0.46356429837369395), 'LOF_3': np.float64(0.7464091500158341), 'LOF_2': np.float64(0.7464091500158341), 'LOF_1': np.float64(0.7464091500158341), 'NN_2': np.float64(0.45992864869332717)}